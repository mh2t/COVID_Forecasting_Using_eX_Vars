{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import urllib.request\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.lines as mlines\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential, Model\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stellargraph as sg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_path = r\"dataset\\adj\\adj1.csv\"\n",
    "x = pd.read_csv(\"dataset/state_X_time_matrix.csv\", index_col=0)\n",
    "y = pd.read_csv(adj_path, index_col=0)\n",
    "sensor_dist_adj = np.matrix(y.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.drop(x.columns[list(range(70))], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_data = x.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_data.head()\n",
    "state_data = state_data.drop([72,73,74,75,76])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_nodes, time_len = state_data.shape\n",
    "print(\"No. of states:\", num_nodes, \"\\nNo of timesteps:\", time_len)\n",
    "\n",
    "state_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(data, train_portion):\n",
    "    time_len = data.shape[1]\n",
    "    train_size = int(time_len * train_portion)\n",
    "    train_data = np.array(data.iloc[:, :train_size])\n",
    "    test_data = np.array(data.iloc[:, train_size:])\n",
    "    return train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rate = 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(state_data, train_rate)\n",
    "print(\"Train data: \", train_data.shape)\n",
    "print(\"Test data: \", test_data.shape)\n",
    "print(\"Adj data: \", sensor_dist_adj.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_data(train_data, test_data):\n",
    "    max_deaths = train_data.max()\n",
    "    min_deaths = train_data.min()\n",
    "    train_scaled = (train_data - min_deaths) / (max_deaths - min_deaths)\n",
    "    test_scaled = (test_data - min_deaths) / (max_deaths - min_deaths)\n",
    "    return train_scaled, test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scaled, test_scaled = scale_data(train_data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 10\n",
    "pre_len = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequence_data_preparation(seq_len, pre_len, train_data, test_data):\n",
    "    trainX, trainY, testX, testY = [], [], [], []\n",
    "\n",
    "    for i in range(train_data.shape[1] - int(seq_len + pre_len - 1)):\n",
    "        a = train_data[:, i : i + seq_len + pre_len]\n",
    "        trainX.append(a[:, :seq_len])\n",
    "        trainY.append(a[:, -1])\n",
    "\n",
    "    for i in range(test_data.shape[1] - int(seq_len + pre_len - 1)):\n",
    "        b = test_data[:, i : i + seq_len + pre_len]\n",
    "        testX.append(b[:, :seq_len])\n",
    "        testY.append(b[:, -1])\n",
    "\n",
    "    trainX = np.array(trainX)\n",
    "    trainY = np.array(trainY)\n",
    "    testX = np.array(testX)\n",
    "    testY = np.array(testY)\n",
    "\n",
    "    return trainX, trainY, testX, testY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX, trainY, testX, testY = sequence_data_preparation(\n",
    "    seq_len, pre_len, train_scaled, test_scaled\n",
    ")\n",
    "print(trainX.shape)\n",
    "print(trainY.shape)\n",
    "print(testX.shape)\n",
    "print(testY.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## StellarGraph Graph Convolution and LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stellargraph.layer import GCN_LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcn_lstm = GCN_LSTM(\n",
    "    seq_len=seq_len,\n",
    "    adj=sensor_dist_adj,\n",
    "    gc_layer_sizes=[32, 8],\n",
    "    gc_activations=[\"relu\", \"relu\"],\n",
    "    lstm_layer_sizes=[150],\n",
    "    lstm_activations=[\"tanh\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_input, x_output = gcn_lstm.in_out_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=x_input, outputs=x_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\", loss=\"mae\", metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    trainX,\n",
    "    trainY,\n",
    "    epochs=250,\n",
    "    batch_size=10,\n",
    "    verbose=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    \"Train loss: \",\n",
    "    history.history[\"loss\"][-1],\n",
    "    \"\\nTest loss:\",\n",
    "#     history.history[\"val_loss\"][-1],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sg.utils.plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ythat = model.predict(trainX)\n",
    "yhat = model.predict(testX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rescale values\n",
    "\n",
    "Rescale the predicted values to the original value range of the timeseries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_deaths = train_data.max()\n",
    "min_deaths = train_data.min()\n",
    "\n",
    "train_rescref = np.array((trainY * (max_deaths - min_deaths)) + min_deaths)\n",
    "test_rescref = np.array((testY * (max_deaths - min_deaths)) + min_deaths)\n",
    "\n",
    "train_rescpred = np.array((ythat * (max_deaths - min_deaths)) + min_deaths)\n",
    "test_rescpred  = np.array((yhat * (max_deaths - min_deaths)) + min_deaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testX.shape\n",
    "test_rescpred.shape\n",
    "test_rescref[0]\n",
    "test_rescpred[0]\n",
    "# yhat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive prediction benchmark (using latest observed value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Naive prediction benchmark (using previous observed value)\n",
    "\n",
    "testnpred = np.array(testX)[\n",
    "    :, :, -1\n",
    "]\n",
    "testnpredc = (testnpred) * max_deaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Performance measures\n",
    "\n",
    "seg_mael = []\n",
    "seg_masel = []\n",
    "seg_nmael = []\n",
    "\n",
    "for j in range(testX.shape[-1]):\n",
    "\n",
    "    seg_mael.append(\n",
    "        np.mean(np.abs(test_rescref.T[j] - test_rescpred.T[j]))\n",
    "    )  # Mean Absolute Error for NN\n",
    "    seg_nmael.append(\n",
    "        np.mean(np.abs(test_rescref.T[j] - testnpredc.T[j]))\n",
    "    )  # Mean Absolute Error for naive prediction\n",
    "    if seg_nmael[-1] != 0:\n",
    "        seg_masel.append(\n",
    "            seg_mael[-1] / seg_nmael[-1]\n",
    "        )  # Ratio of the two: Mean Absolute Scaled Error\n",
    "    else:\n",
    "        seg_masel.append(np.NaN)\n",
    "\n",
    "print(\"Total (ave) MAE for NN: \" + str(np.mean(np.array(seg_mael))))\n",
    "print(\"Total (ave) MAE for naive prediction: \" + str(np.mean(np.array(seg_nmael))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot of actual and predicted deaths on a sample sensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_sum = []\n",
    "pred_sum = []\n",
    "for i in range(len(test_rescpred)):\n",
    "    pred_sum.append(test_rescpred[i].sum())\n",
    "    true_sum.append(test_rescref[i].sum())\n",
    "\n",
    "x = mean_absolute_percentage_error(true_sum,pred_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##all test result visualization\n",
    "fig1 = plt.figure(figsize=(15, 8))\n",
    "#    ax1 = fig1.add_subplot(1,1,1)\n",
    "a_pred = pred_sum\n",
    "a_true = true_sum\n",
    "plt.plot(a_pred, \"r-\", label=\"prediction\")\n",
    "plt.plot(a_true, \"b-\", label=\"true\")\n",
    "plt.xlabel(\"time\")\n",
    "plt.ylabel(\"Deaths\")\n",
    "plt.legend(loc=\"best\", fontsize=10)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
